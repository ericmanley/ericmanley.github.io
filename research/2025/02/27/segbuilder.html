<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>SegBuilder: A Semi-automatic Annotation Tool for Segmentation - Eric Manley</title>
  <meta name="description" content="Academic webpage of Eric Manley">
  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="https://ericmanley.github.io/research/2025/02/27/segbuilder.html">
  <link rel="shortcut icon" type ="image/x-icon" href="https://ericmanley.github.io/favicon.ico">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.css">
  <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">

  <link rel="preconnect" href="https://player.vimeo.com">
  <link rel="preconnect" href="https://i.vimeocdn.com">
  <link rel="preconnect" href="https://f.vimeocdn.com">




<script>
MathJax = {
    tex: {
    inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
    tags: 'ams'  // should be 'ams', 'none', or 'all' }. This line makes the equation numbering and labeling work
    }, 
    svg: {
    fontCache: 'global'
    }
};
</script>
<script
    type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script> 

</head>


  <body>
    <div class="d-flex flex-column min-vh-100"> <!-- Flex container to manage layout height -->

      <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id="
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

<nav class="navbar sticky-top navbar-expand-md navbar-dark bg-dark p-2">
    <a class="navbar-brand" href="https://ericmanley.github.io/">
     <img src="https://ericmanley.github.io/images/initiallogo.png" width=auto height="25" style="margin-right:5px" class="d-inline-block align-top" alt="">
      Eric Manley
    </a>
    <button class="toggler navbar-toggler collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#navbarColor02" aria-controls="navbarColor02" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarColor02">
        <div class="navbar-nav mr-auto">
            <a class="nav-item nav-link" href="https://ericmanley.github.io/">Home</a>
                   
                <a class="nav-item nav-link" href="https://ericmanley.github.io/publications">Publications</a>
                   
                <a class="nav-item nav-link" href="https://ericmanley.github.io/projects">Projects</a>
                   
                <a class="nav-item nav-link" href="https://ericmanley.github.io/teaching">Teaching</a>
            
        </div>
    </div>
</nav>


      <div class="container-fluid flex-grow-1">
        <div class="row">
          <article class="project">
    <h1>SegBuilder: A Semi-automatic Annotation Tool for Segmentation</h1>
    <p><strong>Date:</strong> February 27, 2025</p>
    <p>SegBuilder is a web-based tool that leverages unsupervised segmentation models for semantic segmentation annotation.</p>
    <div>
        <h2 id="relevant-papers-and-presentations">Relevant Papers and Presentations</h2>

<p>We are presenting our peer reviewed <a href="https://openaccess.thecvf.com/content/WACV2025/papers/Reza_SegBuilder_A_Semi-Automatic_Annotation_Tool_for_Segmentation_WACV_2025_paper.pdf">paper</a> at <a href="https://wacv2025.thecvf.com/">WACV 2025</a>. We will also be showing a <a href="https://ericmanley.github.io/images/segbuilder/wacv25poster.pdf">poster</a>.</p>

<p>Our student collaborators, Sean Chen, Sameer Chaudhary, and Jacob Elafros also presented a poster at 2024 CCSC Central Plains where they won the Best Student Poster Award.</p>

<p>The code for SegBuilder is <a href="https://github.com/alimoorreza/segbuilder-v1">available on GitHub</a>.</p>

<ol class="bibliography" reversed="reversed"><li><div class="card mb-4 shadow-sm">
    <div class="row g-0 flex-lg-row-reverse flex-column">
        
        <div class="col-lg-2 d-flex align-items-center justify-content-center">
            <img src="/images/segbuilder_thumb.png" class="img-fluid" alt="SegBuilder: A Semi-Automatic Annotation Tool for Segmentation" />
        </div>
        
        <div class="col-lg-10">
            <div class="card-body">
                <!-- Styled Publication Information -->
                <div class="publication-info">
                    <h5 class="card-title">SegBuilder: A Semi-Automatic Annotation Tool for Segmentation</h5>
                    <p class="card-text">
                        <!-- <strong>Authors:</strong> -->
                        <span>
                            
                                Md Alimoor Reza, 
                            
                                <b>Eric Manley</b>, 
                            
                                Sean Chen, 
                            
                                Sameer Chaudhary, 
                            
                                Jacob Elafros
                            
                        </span>
                        <br />
                        
                            
                                <strong>Proceedings:</strong> <em>Proceedings of the Winter Conference on Applications of Computer Vision (WACV)</em>
                            
                        
                        <br />
                        <strong>Date:</strong> 2025 Feb
                        
                        
                         | <strong>Pages:</strong> 8483-8492
                    </p>
                    </div>
        
            <!-- Buttons -->
            <div class="d-flex flex-wrap gap-2 mt-2">
                
                
        
                
                
                    <a href="https://ericmanley.github.io/papers/2025WACV_SegBuilder.pdf" target="_blank" class="btn btn-primary btn-sm">PDF</a>
                
                
        
                
        
                <!-- Ensure Correct Bootstrap 5 Attributes -->
                <button class="btn btn-primary btn-sm" type="button" data-bs-toggle="collapse" data-bs-target="#apa-reza_wacv2025" aria-expanded="false" aria-controls="apa-reza_wacv2025">CITATION</button>

                <button class="btn btn-primary btn-sm" type="button" data-bs-toggle="collapse" data-bs-target="#bibtex-reza_wacv2025" aria-expanded="false" aria-controls="bibtex-reza_wacv2025">BIBTEX</button>
        
                
                <button class="btn btn-primary btn-sm" type="button" data-bs-toggle="collapse" data-bs-target="#abstract-reza_wacv2025" aria-expanded="false" aria-controls="abstract-reza_wacv2025">ABSTRACT</button>
                

                
                <a href="https://github.com/alimoorreza/segbuilder-v1" target="_blank" class="btn btn-primary btn-sm">CODE</a>
                

                
                <a href="https://ericmanley.github.io/research/2025/02/27/segbuilder.html" target="_blank" class="btn btn-primary btn-sm">READ MORE</a>
                
            </div>
        
            <!-- Collapsible APA -->
            <div class="collapse mt-3" id="apa-reza_wacv2025">
                <div class="card card-body">
                <span id="reza_wacv2025">Reza, M. A., Manley, E., Chen, S., Chaudhary, S., &amp; Elafros, J. (2025). SegBuilder: A Semi-Automatic Annotation Tool for Segmentation. <i>Proceedings of the Winter Conference on Applications of Computer Vision (WACV)</i>, 8483–8492.</span>
                </div>
            </div>

            <!-- Collapsible BibTeX -->
            <div class="collapse mt-3" id="bibtex-reza_wacv2025">
                <div class="card card-body">
                    
                    
                    
                    <pre style="white-space: pre-wrap; overflow-x: auto; max-width: 100%;">@inproceedings{reza_wacv2025,
  author = {Reza, Md Alimoor and Manley, Eric and Chen, Sean and Chaudhary, Sameer and Elafros, Jacob},
  title = {SegBuilder: A Semi-Automatic Annotation Tool for Segmentation},
  booktitle = {Proceedings of the Winter Conference on Applications of Computer Vision (WACV)},
  month = feb,
  year = {2025},
  pages = {8483-8492},
}
</pre>
                </div>
            </div>
        
            <!-- Collapsible Abstract -->
            
                <div class="collapse mt-3" id="abstract-reza_wacv2025">
                <div class="card card-body">
                    This paper addresses the problem of image annotation for segmentation tasks. Semantic segmentation involves labeling each pixel in an image with predefined categories, such as sky, cars, roads, and humans. Deep learning models require numerous annotated images for effective training, but manual annotation is slow and time-consuming. To mitigate this challenge, we leverage the Segment Anything Model (SAM) – a vision foundation model. We introduce SegBuilder, a framework that incorporates SAM to automatically generate segments, which are then tagged by human annotators using a quick selection list. To demonstrate SegBuilder’s effectiveness, we introduced a novel dataset for image segmentation in underwater environments featuring animals such as sea lions, beavers, and jellyfish. Experiments on this dataset showed that SegBuilder significantly speeds up the annotation process compared to the publicly available tool, Label Studio. SegBuilder also includes a free-form drawing tool, allowing users to create correct segments missed by SAM. This feature is particularly useful for scenes with shadows, camouflaged objects, and part-based segmentation tasks where SAM falls short. Experimentally, we demonstrated SegBuilder’s efficacy in these scenarios, showcasing its potential for generating pixel-wise annotations crucial for training robust deep learning models for semantic segmentation.
                </div>
                </div>
            



            </div>
        </div>
        
  </div>
</div></li>
<li><div class="card mb-4 shadow-sm">
    <div class="row g-0 flex-lg-row-reverse flex-column">
        
        <div class="col-md-2 d-flex align-items-center">
            
        </div>
        
        <div class="col-lg-10">
            <div class="card-body">
                <!-- Styled Publication Information -->
                <div class="publication-info">
                    <h5 class="card-title">SegBuilder: Semi-automatic Annotation for Semantic Segmentation (<i>Best Student Poster Award</i>)</h5>
                    <p class="card-text">
                        <!-- <strong>Authors:</strong> -->
                        <span>
                            
                                Sean Chen, 
                            
                                Sameer Chaudhary, 
                            
                                Jacob Elafros, 
                            
                                <b>Eric Manley</b>, 
                            
                                Md. Alimoor Reza
                            
                        </span>
                        <br />
                        
                            
                                <strong>Conference:</strong> <em>Consortium for Computing Sciences in Colleges Central Plains Regional Conference</em>
                            
                        
                        <br />
                        <strong>Date:</strong> 2024 Apr
                        
                        
                        
                    </p>
                    </div>
        
            <!-- Buttons -->
            <div class="d-flex flex-wrap gap-2 mt-2">
                
                
        
                
                
                    <a href="https://ericmanley.github.io/papers/2024CCSC_SegBuilder.pdf" target="_blank" class="btn btn-primary btn-sm">PDF</a>
                
                
        
                
        
                <!-- Ensure Correct Bootstrap 5 Attributes -->
                <button class="btn btn-primary btn-sm" type="button" data-bs-toggle="collapse" data-bs-target="#apa-chen_ccsc2024segbuilder" aria-expanded="false" aria-controls="apa-chen_ccsc2024segbuilder">CITATION</button>

                <button class="btn btn-primary btn-sm" type="button" data-bs-toggle="collapse" data-bs-target="#bibtex-chen_ccsc2024segbuilder" aria-expanded="false" aria-controls="bibtex-chen_ccsc2024segbuilder">BIBTEX</button>
        
                

                

                
            </div>
        
            <!-- Collapsible APA -->
            <div class="collapse mt-3" id="apa-chen_ccsc2024segbuilder">
                <div class="card card-body">
                <span id="chen_ccsc2024segbuilder">Chen, S., Chaudhary, S., Elafros, J., Manley, E., &amp; Reza, M. A. (2024, April). SegBuilder: Semi-automatic Annotation for Semantic Segmentation (<i>Best Student Poster Award</i>). <i>Consortium for Computing Sciences in Colleges Central Plains Regional Conference</i>.</span>
                </div>
            </div>

            <!-- Collapsible BibTeX -->
            <div class="collapse mt-3" id="bibtex-chen_ccsc2024segbuilder">
                <div class="card card-body">
                    
                    
                    
                    <pre style="white-space: pre-wrap; overflow-x: auto; max-width: 100%;">@conference{chen_ccsc2024segbuilder,
  address = {Lamoni, Iowa},
  author = {Chen, Sean and Chaudhary, Sameer and Elafros, Jacob and Manley, Eric and Reza, Md. Alimoor},
  booktitle = {Consortium for Computing Sciences in Colleges Central Plains Regional Conference},
  month = apr,
  title = {{SegBuilder}: Semi-automatic Annotation for Semantic Segmentation (\emph{Best Student Poster Award})},
  year = {2024},
}
</pre>
                </div>
            </div>
        
            <!-- Collapsible Abstract -->
            



            </div>
        </div>
        
  </div>
</div></li></ol>

<h2 id="summary">Summary</h2>

<p><strong>Segmentation</strong> is a computer vision task which attempts to identify which portions of an image belong to different objects. For example, the image on the left shows a scuba diver interacting with a lionfish. If we painted over different parts of the image with different colors, we might produce <em>segments</em> like those shown on the right.</p>

<div class="container">
  <div class="row">
    <center>
<img src="https://ericmanley.github.io/images/segbuilder/diver_lionfish.png" width="400px" alt="scuba diver with lionfish" /><br />
Segmenting an image
</center>
  </div>
</div>
<p><br /></p>

<h3 id="unsupervised-segmentation">Unsupervised Segmentation</h3>

<p>A computer vision model that attempts to automatically produce segments like these without applying any meaning to them is called an <strong>unsupervised segmentation</strong>. Such a model might try to distinguish that some pixels belong to one object and some belong to a different object, but it does not attempt to apply <em>labels</em> to those parts, like “human” or “lionfish”.</p>

<p>There are some <em>very good</em> unsupervised segmentation models that work on general images, like <a href="https://segment-anything.com/">Segment Anything</a> (SAM), an open model released by Meta AI.</p>

<div class="container">
  <div class="row">
    <center>
<img src="https://raw.githubusercontent.com/facebookresearch/segment-anything/refs/heads/main/assets/masks2.jpg" width="400px" /><br />
An image segmented by Segment Anything from <a href="https://github.com/facebookresearch/segment-anything">https://github.com/facebookresearch/segment-anything</a>
</center>
  </div>
</div>
<p><br /></p>

<p>Models like this are good at recognizing when objects are different from one another, but since they do not need to be able to say what those objects are, they can be trained on general image data. It might be able to tell which pixels belong to the lionfish even though it was never trained on any examples of lionfish or even underwater images at all.</p>

<h3 id="semantic-segmentation">Semantic Segmentation</h3>

<p><strong>Semantic Segmentation</strong> is a task in which the image must be segmented into different objects <em>and</em> those objects need to be assigned lables like “human” or “lionfish”. Different applications usually need to be <em>trained</em> on human-annotated images that are specific to the needs of that application. Vision models for self-driving cars need to have labeled segmentation examples for vehicles, pedestrians, lanes, etc. from the perspective of a camera mounted on the car. A model for finding bone fractures in X-ray imagery would need to have lots of labeled segments for different bone X-rays with and without the various kinds of fractures that it needs to detect. Creating the datasets needed to train these models can be extremely slow and labor-intensive, and it usually involves having humans draw polygons on hundreds or thousands of example images.</p>

<div class="container">
  <div class="row">
    <center>
<img src="https://ericmanley.github.io/images/segbuilder/beaver.png" width="400px" alt="underwater image of a beaver" /><br />
Drawing a polygon around a beaver to create dataset for analyzing underwater images
</center>
  </div>
</div>
<p><br /></p>

<h3 id="segbuilder">SegBuilder</h3>

<p>SegBuilder uses an unsupervised model like SAM to produce a starting point for creating datasets that can be used for training semantic segmentation models. SegBuilder presents each starting segment as an image mask that the annotator can perform various actions with.</p>

<div class="container">
  <div class="row">
    <center>
<img src="https://ericmanley.github.io/images/pipeline_fig.png" width="100%" /><br />
A SegBuilder workflow
</center>
  </div>
</div>
<p><br /></p>

<p>In many cases, segments produced by the unsupervised model might perfectly match one of the semantic categories of interest. In this case, the annotator can simply select the appropriate label from a dropdown menu.</p>

<div class="container">
  <div class="row">
    <center>
<img src="https://ericmanley.github.io/images/segbuilder/labeling_interface.png" width="400px" alt="underwater image of a beaver" /><br />
SegBuilder labeling
</center>
  </div>
</div>
<p><br /></p>

<p>However, there are many cases in which the unsupervised model does not accurately capture the intended phenomena. For example, the annotator may be interested in labeling <em>parts</em> of an object that the unsupervised model tends to group together as one big object.</p>

<div class="container">
  <div class="row">
    <center>
<img src="https://ericmanley.github.io/images/segbuilder/part_segmentation.png" width="400px" alt="original images of an airplane and reptile being segmented by SAM and then fixed with SegBuilder" /><br />
Part Segmentation
</center>
  </div>
</div>
<p><br /></p>

<p>In other cases, the unsupervised model misses important things like shadows or camouflaged objects.</p>

<div class="container">
  <div class="row">
    <center>
<img src="https://ericmanley.github.io/images/segbuilder/shadow_camo.png" width="400px" alt="original images of shadows and camouflage objects being segmented by SAM and then fixed with SegBuilder" /><br />
Part Segmentation
</center>
  </div>
</div>
<p><br /></p>

<p>For these cases, SegBuilder allows for new segments to be drawn by the annotator using a natural drawing tool. And, annotators can copy, edit, and adjustment the polygons for any segment produced by the unsupervised model.</p>

<h3 id="evaluation-and-results">Evaluation and Results</h3>

<p>We performed an experiment in which four annotators were tasked with producing datasets for a collections of underwater images with 31 different categories of interest. The annotators first annotated the images using SegBuilder and then using another popular polygon-drawing annotation tool, and we found that SegBuilder resulted in a 3.3x speed-up.</p>

<p>We also peformed experiments with a shadow and camouflage dataset as well as a fine-grained parts dataset and demonstrated a qualitative improvement when compared to SAM-only labeling.</p>

    </div>
</article>
        </div>
      </div>

      

<br/>


<div class="container-footer bg-dark p-2" style="color: white; min-width: 100%;">
		<center><p>&copy 2025 Eric Manley </p></center>
</div>


<script src="/assets/javascript/bootstrap/bootstrap.bundle.min.js"></script>


    </div>

    <script>
      document.addEventListener("DOMContentLoaded", function () {
        document.querySelectorAll('[data-bs-toggle="collapse"]').forEach(button => {
          button.addEventListener("click", function (event) {
            event.preventDefault(); // Prevents interference from other scripts
            let target = document.querySelector(this.getAttribute("data-bs-target"));
            if (target) {
              let bsCollapse = bootstrap.Collapse.getInstance(target);
              if (bsCollapse) {
                bsCollapse.toggle();
              } else {
                new bootstrap.Collapse(target).toggle();
              }
            }
          });
        });
      });
    </script>
  </body>

</html>
